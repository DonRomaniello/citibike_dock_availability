{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TarAppend.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdEJclPmdSYubGw8RLFVVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonRomaniello/citibike_dock_availability/blob/master/TarAppend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju34EaS5hKIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import json\n",
        "import tarfile\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7RnDdmk2ya5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bikepump = pd.read_pickle('./Google Drive/GeneralAssembly/Citibike/Processed/Old.pkl.xz', compression='xz')\n",
        "directory = './Google Drive/GeneralAssembly/Citibike/Processed/Processme'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FpGZ1k4QKIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for filename in os.listdir(directory):\n",
        "  if '.tar.xz' not in filename:\n",
        "    pass\n",
        "  else:\n",
        "    hour_path = directory + '/' + filename\n",
        "    hour = tarfile.open(hour_path)\n",
        "    hour_list = hour.getnames()\n",
        "\n",
        "    for subfile in hour_list:\n",
        "      filthy_data = json.load(hour.extractfile(subfile))\n",
        "      timestamp = filthy_data[\"last_updated\"]\n",
        "      bikepump2 = pd.DataFrame(filthy_data['data']['stations'])\n",
        "\n",
        "      #Sort by station_id\n",
        "      bikepump2.sort_values(by=['station_id'], ascending=True, inplace=True)\n",
        "\n",
        "      #Make a list of columns to remove (all but two)\n",
        "      pre_drop = list(bikepump2.columns)\n",
        "\n",
        "      # Set the index to be Station ID\n",
        "      bikepump2.set_index(['station_id'], drop=True, inplace=True)\n",
        "\n",
        "      # Remove the columns we want from the list\n",
        "      pre_drop.remove('station_id')\n",
        "      pre_drop.remove('num_docks_available')\n",
        "      bikepump2.drop(pre_drop, inplace=True, axis=1)\n",
        "\n",
        "      #Name the columns according to the timestamp on the data\n",
        "      bikepump2.rename(columns={'num_docks_available' : timestamp}, inplace=True)\n",
        "\n",
        "      if bikepump.empty:\n",
        "        bikepump = bikepump2\n",
        "\n",
        "      # Merge the columns, use 'inner' because this means defunct stations are not included\n",
        "      if timestamp not in bikepump.columns:\n",
        "        bikepump = bikepump.merge(bikepump2, how='inner', on='station_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q97r2Ib8_wmj",
        "colab_type": "code",
        "outputId": "c769151f-b7c1-4717-989c-3234589ecef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(bikepump.info())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 927 entries, 116 to 83\n",
            "Columns: 52366 entries, 1580684459 to 1582437599\n",
            "dtypes: int64(52366)\n",
            "memory usage: 370.4+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3Qs_E7OO1Xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Export; despite security concerns I'm using 'pkl' because when I ran json export and import the UNIX time was converted\n",
        "bikepump.to_csv('./Google Drive/GeneralAssembly/Citibike/Processed/Old.csv')\n",
        "bikepump.to_pickle('./Google Drive/GeneralAssembly/Citibike/Processed/Old.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra_tMqmAGrS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bikepump.loc[\"Total Availability\"] = bikepump.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x87E0fUILUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Round epoch to nearest 60 (iles were named based on when wget managed to finish downloading...)\n",
        "\n",
        "round_docks = bikepump.copy(deep=True)\n",
        "round_docks = round_docks.reindex(sorted(round_docks.columns), axis=1)\n",
        "epoch_rename_feed = list(round_docks.columns)\n",
        "epoch_rename_results = []\n",
        "\n",
        "def myround(x, base=60):\n",
        "    return int(base * round(float(x)/base))\n",
        "\n",
        "for sloppy in range(len(epoch_rename_feed)):\n",
        "  if (epoch_rename_feed[sloppy] % 60) != 0:\n",
        "    epoch_rename_feed[sloppy]=myround(epoch_rename_feed[sloppy])\n",
        "\n",
        "round_docks.columns = epoch_rename_feed\n",
        "round_docks.to_csv('./Google Drive/GeneralAssembly/Citibike/Processed/OldRound.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3xdq10EI3FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transpose\n",
        "\n",
        "flip_docks = pd.DataFrame(columns=['TA', 'DT'])\n",
        "flip_docks['TA']=round_docks.loc['Total Availability']\n",
        "flip_docks['DT']=pd.to_datetime(round_docks.columns, unit='s', utc=False)\n",
        "t_docks = round_docks.T\n",
        "t_docks.to_csv('./Google Drive/GeneralAssembly/Citibike/Processed/OldRoundTransposed.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGIdUEShp0uZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!xz -zf --threads=0 ./Google\\ Drive/GeneralAssembly/Citibike/Processed/Old.csv\n",
        "!xz -zf --threads=0 ./Google\\ Drive/GeneralAssembly/Citibike/Processed/Old.pkl\n",
        "!xz -zf --threads=0 ./Google\\ Drive/GeneralAssembly/Citibike/Processed/OldRound.csv\n",
        "!xz -zf --threads=0 ./Google\\ Drive/GeneralAssembly/Citibike/Processed/OldRoundTransposed.csv"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}